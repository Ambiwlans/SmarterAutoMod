[Login]
username = 
password=

refresh_token=
client_id=
client_secret=
user_agent=


[General]
;Your subreddit
subreddit = SpaceX
;Use existing datafile if it exists
use_old_df = True
;How many submissions to scan (100000 comments should provide a solid learning base)
;Reddit's API does not allow you to go beyond 1000 submissions, I may code a work around in some future version but 1000 submissions is pretty good
;100k raw comments  is ~50mb
num_submissions = 1000
;This allows you to ignore threads with special rules by title or name. Plain text or REGEX matching. Case sensitive. No flair is matched with 'None'
ignore_submission_title = (Party Thread|Official Launch|META|Sources Required|Media Thread|Discusses|Moderator|Mod|Update Thread|Updates Thread)
ignore_submission_flair = (relaxed|removed|Removed|META|Meta|Media|Party|Sources Required|Live)

;Ignore users that don't follow normal rules (like bots| mods?)
ignore_user = (Decronym|ElongatedMuskrat|TweetPoster|TweetsInCommentsBot|InstagramMirror|TotesMessenger|Totes_Meta_Bot|SpaceXMirrorBot)

;Ignore late comments to posts (rarely modded) in training in hours after post
ignore_late_comment_age = 96
;Ignore recent comments in hours for training (mods haven't had a chance to check comments made in the past 10 seconds| don't train on it)
ignore_recent_submission_age = 48
;Ignore dead threads and super heavy threads (typically not well policed)
ignore_min_co = 10
ignore_max_co = 1000

;Ignore certain comments by content (to allow automod to catch with notifications)
;Use: r/SpaceX ignores ITAR violations and a couple bots in order for automod to notify us of these comments
;You could also just put any automod catches in here to let automod deal with them.... This only accepts a single regex string though, so lots of | ors
;Example: (fuck ze mods|fuck ze other mods)
ignore_comment_content = (approved supplier list|quality clause attachment for purchase orders|returnable packaging standard|spacex documentation checklist|supplier information for spacex vendors|supplier information for all spacex vendors|supplier manual|supplier request form|supplier shipping packaging and preservation|supplier survey form|RemindMe)

[Processing]

;Allows you to ensure the machine finds certain regex matches in comments.
;Useful for colocations, complex regex or multi-token strings. Single words are found already
;Note: These can dramatically slow down processing, use sparingly.
;Example : "need a bigger","mass effect", "fly safe", "?m(u|e)rica!?", "checks out"
;custom_regex_matches = "need a bigger","mass effect", "fly safe", "?m(u|e)rica!?", "checks out", "bouncy castle", "mark watney","James Cameron","educate yourself","possibly go wrong", "troll________________", "fanboi_____________", "you suck", "!______",do you even, trim 3x repeats into 2,

;How many feature words to look at 500~2500 is best but expect to take up 2MB per 1000 comments collected @500| 10MB @2500. Learning time will also increase slightly
;Max suggestion is the number of comments/50 ... comments/100 is probably decent (the hyperparameters are tuned for 1000)
num_ft_words = 1000

;You can try stemming if you want. 
;stemming = False

[Training]


[Execution]
;ROUGHLY what FPR you are accepting. This system will likely overreport for the few few hundred comments
;Int 1~99
report_fpr = 5
remove_fpr = 1

;Hyperparameters. Do not touch unless you know what you're doing
n_estimators=0
max_depth=0
min_samples_split=0
min_samples_leaf=0
max_leaf_nodes=0
min_weight_fraction_leaf=0

[Debug]
;Print out more errors
verbose=True

;How much data (#comments) should be processed/trained on (smaller subsets to test faster). 0 = all data available
data_size=0